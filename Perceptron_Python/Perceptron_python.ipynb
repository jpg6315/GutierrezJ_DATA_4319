{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# The Perceptron Learning Algorithm\n",
    " \n",
    "## Learning And Machine Learning\n",
    "   Learning is the ability to improve one's behavior with experience. In focusing on the experience aspect of learning, machine learning can be be defined as building computers, systems that automatically improve with experience.\n",
    "   A typical algorithm solves a problem by giving a computer data and a program to give a suitable output. Machine learning involves giving the data  and examples of outcomes to the computer to output a model for getting suitable\n",
    "outputs.\n",
    "\n",
    "\n",
    "<img align=\"center\" width=\"500\" height=\"300\" src=\"PLA.png\">\n",
    "\n",
    "\n",
    "## Synopsis of The Perceptron  \n",
    "   The Perceptron learning algorithm is an algorithm that is used for supervised learning of binary clusters.The supervised learning involves giving conditions(inputs) with documented outputs. An allusion of learning and the binary clusters means that the choice of output has only two outcomes. The Perceptron was invented in 1957 by Frank Rosenblatt Ph.D. The idea is that the Perceptron works just like the neuron of a nervous system. Each neuron receives thousands of signals from other neurons, connected via synapses. Once the sum of the signals being received surpasses a certain threshold, a response is sent through the axon.\n",
    "\n",
    "\n",
    "## Composition of the Perceptron Learning Algorithm\n",
    "The implementation of the perceptron learning algorithm involves using a collection of features to answer a question that has two choices; binary cluster. And the algorithm learns to make these choices from being exposed to previous data collected with resultant outcomes with one of the two choices. \n",
    "So what we have actualy is:\n",
    "$\\mathcal{X} \\subseteq \\mathbb{R}^d$ and $d \\in \\mathbb{N}$ be the input space, and let $\\mathcal{Y} = \\{-1, 1\\}$ \n",
    " $x$: Input customer information that is used to make credit decision.\n",
    "* $f:\\mathcal{X} \\rightarrow \\mathcal{Y}$: *Unknown target* function that is the ideal formula for credit approval. \n",
    "* $\\mathcal{X}$: *Input space* consisting of all possible input $x$.\n",
    "* $\\mathcal{Y}$: *Output space* consisting of no or yes credit approval.\n",
    "* $\\mathcal{D}$: *Data set* of tuples in  input-output examples of the form $(x_i, y_i)$, where $f(x_i) = y_i$ and $i \\in \\mathbb{N}$ .\n",
    "* $\\mathcal{A}$: Learning algorithm which uses $D$ to pick a formula (hypothesis) $g:\\mathcal{X}\\rightarrow \\mathcal{Y}$ so that $g\\approx f$, where $g\\in \\mathcal{H}$. Here $\\mathcal{H}$ is the *hypothesis space*. \n",
    "\n",
    "For $h \\in \\mathcal{H}$, $h(x)$ gives different weights to the different coordinates of $x$. This reflects the relative importance of each coordinate to the credit decision. The combinded weighted coordinates form a credit score which is compared to some threshold, say $theta$. \n",
    "\n",
    "* Approve if\n",
    "$$\n",
    "\\sum_{i=1}^{d}w_ix_i > \\theta\n",
    "$$\n",
    "\n",
    "* Deny if\n",
    "$$\n",
    "\\sum_{i=1}^{d}w_ix_i < \\theta\n",
    "$$\n",
    "\n",
    "We next introduce a *bias* $- b = \\theta$, and so, we build the following form for hypothesis functions in $\\mathcal{H}$.\n",
    "\n",
    "$$\n",
    "h(x) = \\text{sign}\\Big((\\sum_{i=1}^{d}w_ix_i) + b\\Big), \n",
    "$$\n",
    "\n",
    "where $h(x) = 1$ means approve and $h(x) = -1 $ means deny. \n",
    "\n",
    "We next simplify notation by treating the bias $b$ as a weight, and modify $x$ so that \n",
    "\n",
    "$$\n",
    "w = [b, w_1, \\dots, w_d]^{T}\n",
    "$$\n",
    "\n",
    "$$\n",
    "x = [1.0, x_1, \\dots, x_d]^{T}\n",
    "$$\n",
    "\n",
    "Thus, $\\mathcal{X} = {1.0}\\times\\mathbb{R}^d$, and $h(x) = \\text{sign}(w^{T}x)$. \n",
    "\n",
    "### Perceptron Learning Algorithm (PLA)\n",
    "This is an iterative method. Suppose an example from $(x_1,y_1), \\dots, (x_N, y_N)$ is currently misclassifed at time $t$, and denote this misclassifed example by $(x(t), y(t))$. Note that since $(x(t), y(t))$ is currently misclassifed, \n",
    "\n",
    "$$\n",
    "y(t) \\neq \\text{sign}(w^{T}(t)x(t)). \n",
    "$$\n",
    "\n",
    "**Update Rule:**\n",
    "\n",
    "$$\n",
    "w(t+1) = w(t) + y(t)x(t).\n",
    "$$\n",
    "\n",
    "**Theorem.** The perceptron model will always classify the training examples correctly when the data is linearly seperable. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    SepalLength  SepalWidth  PetalLength  PetalWidth     Species\n",
      "0           6.2         2.2          4.5         1.5  versicolor\n",
      "1           6.6         2.9          4.6         1.3  versicolor\n",
      "2           5.1         3.8          1.5         0.3      setosa\n",
      "3           4.9         3.6          1.4         0.1      setosa\n",
      "4           5.1         2.5          3.0         1.1  versicolor\n",
      "5           5.1         3.3          1.7         0.5      setosa\n",
      "6           6.1         3.0          4.6         1.4  versicolor\n",
      "7           6.0         2.2          4.0         1.0  versicolor\n",
      "8           6.0         2.9          4.5         1.5  versicolor\n",
      "9           5.8         4.0          1.2         0.2      setosa\n",
      "10          4.3         3.0          1.1         0.1      setosa\n",
      "11          5.6         2.5          3.9         1.1  versicolor\n",
      "12          5.0         2.0          3.5         1.0  versicolor\n",
      "13          6.1         2.8          4.0         1.3  versicolor\n",
      "14          5.1         3.4          1.5         0.2      setosa\n",
      "15          5.7         2.8          4.5         1.3  versicolor\n",
      "16          5.5         3.5          1.3         0.2      setosa\n",
      "17          6.3         3.3          4.7         1.6  versicolor\n",
      "18          5.8         2.7          4.1         1.0  versicolor\n",
      "19          5.0         3.3          1.4         0.2      setosa\n",
      "20          4.8         3.1          1.6         0.2      setosa\n",
      "21          6.1         2.8          4.7         1.2  versicolor\n",
      "22          5.0         3.0          1.6         0.2      setosa\n",
      "23          4.8         3.0          1.4         0.1      setosa\n",
      "24          4.8         3.4          1.9         0.2      setosa\n",
      "25          6.0         2.7          5.1         1.6  versicolor\n",
      "26          4.6         3.2          1.4         0.2      setosa\n",
      "27          5.7         2.9          4.2         1.3  versicolor\n",
      "28          6.8         2.8          4.8         1.4  versicolor\n",
      "29          6.9         3.1          4.9         1.5  versicolor\n",
      "..          ...         ...          ...         ...         ...\n",
      "70          5.7         3.0          4.2         1.2  versicolor\n",
      "71          5.2         4.1          1.5         0.1      setosa\n",
      "72          6.4         2.9          4.3         1.3  versicolor\n",
      "73          6.3         2.3          4.4         1.3  versicolor\n",
      "74          5.0         3.4          1.5         0.2      setosa\n",
      "75          5.7         2.8          4.1         1.3  versicolor\n",
      "76          5.5         2.4          3.8         1.1  versicolor\n",
      "77          5.4         3.9          1.7         0.4      setosa\n",
      "78          4.9         3.1          1.5         0.2      setosa\n",
      "79          6.4         3.2          4.5         1.5  versicolor\n",
      "80          4.5         2.3          1.3         0.3      setosa\n",
      "81          6.7         3.1          4.7         1.5  versicolor\n",
      "82          4.9         3.0          1.4         0.2      setosa\n",
      "83          5.8         2.6          4.0         1.2  versicolor\n",
      "84          5.0         3.6          1.4         0.2      setosa\n",
      "85          4.6         3.4          1.4         0.3      setosa\n",
      "86          6.7         3.0          5.0         1.7  versicolor\n",
      "87          6.1         2.9          4.7         1.4  versicolor\n",
      "88          5.0         2.3          3.3         1.0  versicolor\n",
      "89          6.5         2.8          4.6         1.5  versicolor\n",
      "90          6.7         3.1          4.4         1.4  versicolor\n",
      "91          5.5         2.4          3.7         1.0  versicolor\n",
      "92          6.6         3.0          4.4         1.4  versicolor\n",
      "93          6.0         3.4          4.5         1.6  versicolor\n",
      "94          7.0         3.2          4.7         1.4  versicolor\n",
      "95          5.2         3.5          1.5         0.2      setosa\n",
      "96          4.8         3.0          1.4         0.3      setosa\n",
      "97          5.6         3.0          4.5         1.5  versicolor\n",
      "98          5.0         3.4          1.6         0.4      setosa\n",
      "99          5.1         3.8          1.9         0.4      setosa\n",
      "\n",
      "[100 rows x 5 columns]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "df = pd.read_csv('iris_data.csv')\n",
    "df = df[0:100]\n",
    "#shuffled the data to include all all observations\n",
    "df = df[0:100].sample(frac=1).reset_index(drop=True)\n",
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get sepal length and petal lenght from the iris data set \n",
    "X = [np.array([1.0, df['SepalLength'][i], df['PetalLength'][i]]) for i in range(99)]\n",
    "\n",
    "# Convert the species label to a numeric valua\n",
    "make_int = lambda label: 1 if label == 'setosa' else -1\n",
    "Y = [make_int(df['Species'][i]) for i in range(99)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    " #Set perceptron hypothesis: h(x) = sign(w^T*x)\n",
    "def h(w, x):\n",
    "    if w @ x > 0:\n",
    "        return 1\n",
    "    else:\n",
    "        return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Perceptron(x, y, iterations = 1000):\n",
    "    \n",
    "    w = np.random.rand(3)      #initializing the weights \n",
    "    n = len(x)\n",
    "    \n",
    "    for _ in range(iterations):\n",
    "        i = np.random.randint(n)\n",
    "        if h(w, x[i]) != y[i]:\n",
    "            w += y[i]*x[i]\n",
    "    \n",
    "    return w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate the perceptron learning algorithm 1000 times \n",
    "w = Perceptron(X, Y, 10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(w, i):\n",
    "    if h(w, X[i]) == 1:\n",
    "        return 'Setosa'\n",
    "    else:\n",
    "        return 'Versicolor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Setosa'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict(w, 20)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

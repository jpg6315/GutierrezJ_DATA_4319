{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img align=\"left\" width=\"1000\" height=\"100\" src=\"MLPtitle.png\">\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A multilayer perceptrons(MLP) is a ﬁnite directed acyclic graph. The nodes are logistically activated.\n",
    "The nodes are neurons with logistic activation. A multilayer perceptron (MLP) is a deep, artificial neural network. It is composed of more than one perceptron. They are composed of an input layer to receive the signal, an output layer that makes a decision or prediction about the input, and in between those two, an arbitrary number of hidden layers that are the true computational engine of the MLP. MLPs with one hidden layer are capable of approximating any continuous function.\n",
    "&nbsp;\n",
    "&nbsp; \n",
    "\n",
    "Multilayer perceptrons are often applied to supervised learning problems. They train on a set of input-output pairs and learn to model the correlation (or dependencies) between those inputs and outputs. Training involves adjusting the parameters, or the weights and biases, of the model in order to minimize error. Backpropagation is used to make those weigh and bias adjustments relative to the error, and the error itself can be measured in a variety of ways, including by root mean squared error (RMSE).\n",
    "&nbsp;\n",
    "&nbsp; \n",
    "\n",
    "In the forward pass, the signal flow moves from the input layer through the hidden layers to the output layer, and the decision of the output layer is measured against the ground truth labels.  In the backward pass, using backpropagation and the chain rule of calculus, partial derivatives of the error function w.r.t. the various weights and biases are back-propagated through the MLP. That act of differentiation gives us a gradient, or a landscape of error, along which the parameters may be adjusted as they move the MLP one step closer to the error minimum. This can be done with any gradient-based optimisation algorithm such as stochastic gradient descent. The network keeps playing that game of tennis until the error can go no lower. This state is known as convergence.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150×5 DataFrames.DataFrame\n",
      "│ Row │ SepalLength │ SepalWidth │ PetalLength │ PetalWidth │ Species    │\n",
      "│     │ \u001b[90mFloat64⍰\u001b[39m    │ \u001b[90mFloat64⍰\u001b[39m   │ \u001b[90mFloat64⍰\u001b[39m    │ \u001b[90mFloat64⍰\u001b[39m   │ \u001b[90mString⍰\u001b[39m    │\n",
      "├─────┼─────────────┼────────────┼─────────────┼────────────┼────────────┤\n",
      "│ 1   │ 5.1         │ 3.5        │ 1.4         │ 0.2        │ setosa     │\n",
      "│ 2   │ 4.9         │ 3.0        │ 1.4         │ 0.2        │ setosa     │\n",
      "│ 3   │ 4.7         │ 3.2        │ 1.3         │ 0.2        │ setosa     │\n",
      "│ 4   │ 4.6         │ 3.1        │ 1.5         │ 0.2        │ setosa     │\n",
      "│ 5   │ 5.0         │ 3.6        │ 1.4         │ 0.2        │ setosa     │\n",
      "│ 6   │ 5.4         │ 3.9        │ 1.7         │ 0.4        │ setosa     │\n",
      "│ 7   │ 4.6         │ 3.4        │ 1.4         │ 0.3        │ setosa     │\n",
      "│ 8   │ 5.0         │ 3.4        │ 1.5         │ 0.2        │ setosa     │\n",
      "│ 9   │ 4.4         │ 2.9        │ 1.4         │ 0.2        │ setosa     │\n",
      "│ 10  │ 4.9         │ 3.1        │ 1.5         │ 0.1        │ setosa     │\n",
      "│ 11  │ 5.4         │ 3.7        │ 1.5         │ 0.2        │ setosa     │\n",
      "│ 12  │ 4.8         │ 3.4        │ 1.6         │ 0.2        │ setosa     │\n",
      "│ 13  │ 4.8         │ 3.0        │ 1.4         │ 0.1        │ setosa     │\n",
      "│ 14  │ 4.3         │ 3.0        │ 1.1         │ 0.1        │ setosa     │\n",
      "│ 15  │ 5.8         │ 4.0        │ 1.2         │ 0.2        │ setosa     │\n",
      "│ 16  │ 5.7         │ 4.4        │ 1.5         │ 0.4        │ setosa     │\n",
      "│ 17  │ 5.4         │ 3.9        │ 1.3         │ 0.4        │ setosa     │\n",
      "│ 18  │ 5.1         │ 3.5        │ 1.4         │ 0.3        │ setosa     │\n",
      "│ 19  │ 5.7         │ 3.8        │ 1.7         │ 0.3        │ setosa     │\n",
      "│ 20  │ 5.1         │ 3.8        │ 1.5         │ 0.3        │ setosa     │\n",
      "│ 21  │ 5.4         │ 3.4        │ 1.7         │ 0.2        │ setosa     │\n",
      "│ 22  │ 5.1         │ 3.7        │ 1.5         │ 0.4        │ setosa     │\n",
      "│ 23  │ 4.6         │ 3.6        │ 1.0         │ 0.2        │ setosa     │\n",
      "│ 24  │ 5.1         │ 3.3        │ 1.7         │ 0.5        │ setosa     │\n",
      "│ 25  │ 4.8         │ 3.4        │ 1.9         │ 0.2        │ setosa     │\n",
      "│ 26  │ 5.0         │ 3.0        │ 1.6         │ 0.2        │ setosa     │\n",
      "│ 27  │ 5.0         │ 3.4        │ 1.6         │ 0.4        │ setosa     │\n",
      "│ 28  │ 5.2         │ 3.5        │ 1.5         │ 0.2        │ setosa     │\n",
      "│ 29  │ 5.2         │ 3.4        │ 1.4         │ 0.2        │ setosa     │\n",
      "│ 30  │ 4.7         │ 3.2        │ 1.6         │ 0.2        │ setosa     │\n",
      "│ 31  │ 4.8         │ 3.1        │ 1.6         │ 0.2        │ setosa     │\n",
      "│ 32  │ 5.4         │ 3.4        │ 1.5         │ 0.4        │ setosa     │\n",
      "│ 33  │ 5.2         │ 4.1        │ 1.5         │ 0.1        │ setosa     │\n",
      "│ 34  │ 5.5         │ 4.2        │ 1.4         │ 0.2        │ setosa     │\n",
      "│ 35  │ 4.9         │ 3.1        │ 1.5         │ 0.2        │ setosa     │\n",
      "│ 36  │ 5.0         │ 3.2        │ 1.2         │ 0.2        │ setosa     │\n",
      "│ 37  │ 5.5         │ 3.5        │ 1.3         │ 0.2        │ setosa     │\n",
      "│ 38  │ 4.9         │ 3.6        │ 1.4         │ 0.1        │ setosa     │\n",
      "│ 39  │ 4.4         │ 3.0        │ 1.3         │ 0.2        │ setosa     │\n",
      "│ 40  │ 5.1         │ 3.4        │ 1.5         │ 0.2        │ setosa     │\n",
      "│ 41  │ 5.0         │ 3.5        │ 1.3         │ 0.3        │ setosa     │\n",
      "│ 42  │ 4.5         │ 2.3        │ 1.3         │ 0.3        │ setosa     │\n",
      "│ 43  │ 4.4         │ 3.2        │ 1.3         │ 0.2        │ setosa     │\n",
      "│ 44  │ 5.0         │ 3.5        │ 1.6         │ 0.6        │ setosa     │\n",
      "│ 45  │ 5.1         │ 3.8        │ 1.9         │ 0.4        │ setosa     │\n",
      "│ 46  │ 4.8         │ 3.0        │ 1.4         │ 0.3        │ setosa     │\n",
      "│ 47  │ 5.1         │ 3.8        │ 1.6         │ 0.2        │ setosa     │\n",
      "│ 48  │ 4.6         │ 3.2        │ 1.4         │ 0.2        │ setosa     │\n",
      "│ 49  │ 5.3         │ 3.7        │ 1.5         │ 0.2        │ setosa     │\n",
      "│ 50  │ 5.0         │ 3.3        │ 1.4         │ 0.2        │ setosa     │\n",
      "│ 51  │ 7.0         │ 3.2        │ 4.7         │ 1.4        │ versicolor │\n",
      "│ 52  │ 6.4         │ 3.2        │ 4.5         │ 1.5        │ versicolor │\n",
      "│ 53  │ 6.9         │ 3.1        │ 4.9         │ 1.5        │ versicolor │\n",
      "│ 54  │ 5.5         │ 2.3        │ 4.0         │ 1.3        │ versicolor │\n",
      "│ 55  │ 6.5         │ 2.8        │ 4.6         │ 1.5        │ versicolor │\n",
      "│ 56  │ 5.7         │ 2.8        │ 4.5         │ 1.3        │ versicolor │\n",
      "│ 57  │ 6.3         │ 3.3        │ 4.7         │ 1.6        │ versicolor │\n",
      "│ 58  │ 4.9         │ 2.4        │ 3.3         │ 1.0        │ versicolor │\n",
      "│ 59  │ 6.6         │ 2.9        │ 4.6         │ 1.3        │ versicolor │\n",
      "│ 60  │ 5.2         │ 2.7        │ 3.9         │ 1.4        │ versicolor │\n",
      "│ 61  │ 5.0         │ 2.0        │ 3.5         │ 1.0        │ versicolor │\n",
      "│ 62  │ 5.9         │ 3.0        │ 4.2         │ 1.5        │ versicolor │\n",
      "│ 63  │ 6.0         │ 2.2        │ 4.0         │ 1.0        │ versicolor │\n",
      "│ 64  │ 6.1         │ 2.9        │ 4.7         │ 1.4        │ versicolor │\n",
      "│ 65  │ 5.6         │ 2.9        │ 3.6         │ 1.3        │ versicolor │\n",
      "│ 66  │ 6.7         │ 3.1        │ 4.4         │ 1.4        │ versicolor │\n",
      "│ 67  │ 5.6         │ 3.0        │ 4.5         │ 1.5        │ versicolor │\n",
      "│ 68  │ 5.8         │ 2.7        │ 4.1         │ 1.0        │ versicolor │\n",
      "│ 69  │ 6.2         │ 2.2        │ 4.5         │ 1.5        │ versicolor │\n",
      "│ 70  │ 5.6         │ 2.5        │ 3.9         │ 1.1        │ versicolor │\n",
      "│ 71  │ 5.9         │ 3.2        │ 4.8         │ 1.8        │ versicolor │\n",
      "│ 72  │ 6.1         │ 2.8        │ 4.0         │ 1.3        │ versicolor │\n",
      "│ 73  │ 6.3         │ 2.5        │ 4.9         │ 1.5        │ versicolor │\n",
      "│ 74  │ 6.1         │ 2.8        │ 4.7         │ 1.2        │ versicolor │\n",
      "│ 75  │ 6.4         │ 2.9        │ 4.3         │ 1.3        │ versicolor │\n",
      "│ 76  │ 6.6         │ 3.0        │ 4.4         │ 1.4        │ versicolor │\n",
      "│ 77  │ 6.8         │ 2.8        │ 4.8         │ 1.4        │ versicolor │\n",
      "│ 78  │ 6.7         │ 3.0        │ 5.0         │ 1.7        │ versicolor │\n",
      "│ 79  │ 6.0         │ 2.9        │ 4.5         │ 1.5        │ versicolor │\n",
      "│ 80  │ 5.7         │ 2.6        │ 3.5         │ 1.0        │ versicolor │\n",
      "│ 81  │ 5.5         │ 2.4        │ 3.8         │ 1.1        │ versicolor │\n",
      "│ 82  │ 5.5         │ 2.4        │ 3.7         │ 1.0        │ versicolor │\n",
      "│ 83  │ 5.8         │ 2.7        │ 3.9         │ 1.2        │ versicolor │\n",
      "│ 84  │ 6.0         │ 2.7        │ 5.1         │ 1.6        │ versicolor │\n",
      "│ 85  │ 5.4         │ 3.0        │ 4.5         │ 1.5        │ versicolor │\n",
      "│ 86  │ 6.0         │ 3.4        │ 4.5         │ 1.6        │ versicolor │\n",
      "│ 87  │ 6.7         │ 3.1        │ 4.7         │ 1.5        │ versicolor │\n",
      "│ 88  │ 6.3         │ 2.3        │ 4.4         │ 1.3        │ versicolor │\n",
      "│ 89  │ 5.6         │ 3.0        │ 4.1         │ 1.3        │ versicolor │\n",
      "│ 90  │ 5.5         │ 2.5        │ 4.0         │ 1.3        │ versicolor │\n",
      "│ 91  │ 5.5         │ 2.6        │ 4.4         │ 1.2        │ versicolor │\n",
      "│ 92  │ 6.1         │ 3.0        │ 4.6         │ 1.4        │ versicolor │\n",
      "│ 93  │ 5.8         │ 2.6        │ 4.0         │ 1.2        │ versicolor │\n",
      "│ 94  │ 5.0         │ 2.3        │ 3.3         │ 1.0        │ versicolor │\n",
      "│ 95  │ 5.6         │ 2.7        │ 4.2         │ 1.3        │ versicolor │\n",
      "│ 96  │ 5.7         │ 3.0        │ 4.2         │ 1.2        │ versicolor │\n",
      "│ 97  │ 5.7         │ 2.9        │ 4.2         │ 1.3        │ versicolor │\n",
      "│ 98  │ 6.2         │ 2.9        │ 4.3         │ 1.3        │ versicolor │\n",
      "│ 99  │ 5.1         │ 2.5        │ 3.0         │ 1.1        │ versicolor │\n",
      "│ 100 │ 5.7         │ 2.8        │ 4.1         │ 1.3        │ versicolor │\n",
      "│ 101 │ 6.3         │ 3.3        │ 6.0         │ 2.5        │ virginica  │\n",
      "│ 102 │ 5.8         │ 2.7        │ 5.1         │ 1.9        │ virginica  │\n",
      "│ 103 │ 7.1         │ 3.0        │ 5.9         │ 2.1        │ virginica  │\n",
      "│ 104 │ 6.3         │ 2.9        │ 5.6         │ 1.8        │ virginica  │\n",
      "│ 105 │ 6.5         │ 3.0        │ 5.8         │ 2.2        │ virginica  │\n",
      "│ 106 │ 7.6         │ 3.0        │ 6.6         │ 2.1        │ virginica  │\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "│ 107 │ 4.9         │ 2.5        │ 4.5         │ 1.7        │ virginica  │\n",
      "│ 108 │ 7.3         │ 2.9        │ 6.3         │ 1.8        │ virginica  │\n",
      "│ 109 │ 6.7         │ 2.5        │ 5.8         │ 1.8        │ virginica  │\n",
      "│ 110 │ 7.2         │ 3.6        │ 6.1         │ 2.5        │ virginica  │\n",
      "│ 111 │ 6.5         │ 3.2        │ 5.1         │ 2.0        │ virginica  │\n",
      "│ 112 │ 6.4         │ 2.7        │ 5.3         │ 1.9        │ virginica  │\n",
      "│ 113 │ 6.8         │ 3.0        │ 5.5         │ 2.1        │ virginica  │\n",
      "│ 114 │ 5.7         │ 2.5        │ 5.0         │ 2.0        │ virginica  │\n",
      "│ 115 │ 5.8         │ 2.8        │ 5.1         │ 2.4        │ virginica  │\n",
      "│ 116 │ 6.4         │ 3.2        │ 5.3         │ 2.3        │ virginica  │\n",
      "│ 117 │ 6.5         │ 3.0        │ 5.5         │ 1.8        │ virginica  │\n",
      "│ 118 │ 7.7         │ 3.8        │ 6.7         │ 2.2        │ virginica  │\n",
      "│ 119 │ 7.7         │ 2.6        │ 6.9         │ 2.3        │ virginica  │\n",
      "│ 120 │ 6.0         │ 2.2        │ 5.0         │ 1.5        │ virginica  │\n",
      "│ 121 │ 6.9         │ 3.2        │ 5.7         │ 2.3        │ virginica  │\n",
      "│ 122 │ 5.6         │ 2.8        │ 4.9         │ 2.0        │ virginica  │\n",
      "│ 123 │ 7.7         │ 2.8        │ 6.7         │ 2.0        │ virginica  │\n",
      "│ 124 │ 6.3         │ 2.7        │ 4.9         │ 1.8        │ virginica  │\n",
      "│ 125 │ 6.7         │ 3.3        │ 5.7         │ 2.1        │ virginica  │\n",
      "│ 126 │ 7.2         │ 3.2        │ 6.0         │ 1.8        │ virginica  │\n",
      "│ 127 │ 6.2         │ 2.8        │ 4.8         │ 1.8        │ virginica  │\n",
      "│ 128 │ 6.1         │ 3.0        │ 4.9         │ 1.8        │ virginica  │\n",
      "│ 129 │ 6.4         │ 2.8        │ 5.6         │ 2.1        │ virginica  │\n",
      "│ 130 │ 7.2         │ 3.0        │ 5.8         │ 1.6        │ virginica  │\n",
      "│ 131 │ 7.4         │ 2.8        │ 6.1         │ 1.9        │ virginica  │\n",
      "│ 132 │ 7.9         │ 3.8        │ 6.4         │ 2.0        │ virginica  │\n",
      "│ 133 │ 6.4         │ 2.8        │ 5.6         │ 2.2        │ virginica  │\n",
      "│ 134 │ 6.3         │ 2.8        │ 5.1         │ 1.5        │ virginica  │\n",
      "│ 135 │ 6.1         │ 2.6        │ 5.6         │ 1.4        │ virginica  │\n",
      "│ 136 │ 7.7         │ 3.0        │ 6.1         │ 2.3        │ virginica  │\n",
      "│ 137 │ 6.3         │ 3.4        │ 5.6         │ 2.4        │ virginica  │\n",
      "│ 138 │ 6.4         │ 3.1        │ 5.5         │ 1.8        │ virginica  │\n",
      "│ 139 │ 6.0         │ 3.0        │ 4.8         │ 1.8        │ virginica  │\n",
      "│ 140 │ 6.9         │ 3.1        │ 5.4         │ 2.1        │ virginica  │\n",
      "│ 141 │ 6.7         │ 3.1        │ 5.6         │ 2.4        │ virginica  │\n",
      "│ 142 │ 6.9         │ 3.1        │ 5.1         │ 2.3        │ virginica  │\n",
      "│ 143 │ 5.8         │ 2.7        │ 5.1         │ 1.9        │ virginica  │\n",
      "│ 144 │ 6.8         │ 3.2        │ 5.9         │ 2.3        │ virginica  │\n",
      "│ 145 │ 6.7         │ 3.3        │ 5.7         │ 2.5        │ virginica  │\n",
      "│ 146 │ 6.7         │ 3.0        │ 5.2         │ 2.3        │ virginica  │\n",
      "│ 147 │ 6.3         │ 2.5        │ 5.0         │ 1.9        │ virginica  │\n",
      "│ 148 │ 6.5         │ 3.0        │ 5.2         │ 2.0        │ virginica  │\n",
      "│ 149 │ 6.2         │ 3.4        │ 5.4         │ 2.3        │ virginica  │\n",
      "│ 150 │ 5.9         │ 3.0        │ 5.1         │ 1.8        │ virginica  │\n"
     ]
    }
   ],
   "source": [
    "import CSV\n",
    "\n",
    "iris = CSV.read(\"iris_data.csv\")   ## NOTE \"CSV\" MUST BE CAPITALIZED\n",
    "println(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = zeros(4, 150)\n",
    "Y = zeros(3, 150)\n",
    "\n",
    "for i = 1:150\n",
    "    for j = 1:4\n",
    "        X[j, i] = iris[i, j]\n",
    "        if iris[i , 5] == \"setosa\"\n",
    "            Y[1, i] = 1.0\n",
    "        elseif iris[i, 5] == \"versicolor\"\n",
    "            Y[2, i] = 1.0\n",
    "        else\n",
    "            Y[3, i] = 1.0\n",
    "        end\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<p>DataFrameRow</p><table class=\"data-frame\"><thead><tr><th></th><th>SepalLength</th><th>SepalWidth</th><th>PetalLength</th><th>PetalWidth</th><th>Species</th></tr><tr><th></th><th>Float64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>Float64⍰</th><th>String⍰</th></tr></thead><tbody><p>1 rows × 5 columns</p><tr><th>90</th><td>5.5</td><td>2.5</td><td>4.0</td><td>1.3</td><td>versicolor</td></tr></tbody></table>"
      ],
      "text/latex": [
       "\\begin{tabular}{r|ccccc}\n",
       "\t& SepalLength & SepalWidth & PetalLength & PetalWidth & Species\\\\\n",
       "\t\\hline\n",
       "\t& Float64⍰ & Float64⍰ & Float64⍰ & Float64⍰ & String⍰\\\\\n",
       "\t\\hline\n",
       "\t90 & 5.5 & 2.5 & 4.0 & 1.3 & versicolor \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "DataFrameRow\n",
       "│ Row │ SepalLength │ SepalWidth │ PetalLength │ PetalWidth │ Species    │\n",
       "│     │ \u001b[90mFloat64⍰\u001b[39m    │ \u001b[90mFloat64⍰\u001b[39m   │ \u001b[90mFloat64⍰\u001b[39m    │ \u001b[90mFloat64⍰\u001b[39m   │ \u001b[90mString⍰\u001b[39m    │\n",
       "├─────┼─────────────┼────────────┼─────────────┼────────────┼────────────┤\n",
       "│ 90  │ 5.5         │ 2.5        │ 4.0         │ 1.3        │ versicolor │"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris[90,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4-element Array{Float64,1}:\n",
       " 5.5\n",
       " 2.5\n",
       " 4.0\n",
       " 1.3"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:,90]     # going to compare with the 90th column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Float64,1}:\n",
       " 0.0\n",
       " 1.0\n",
       " 0.0"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[:,90]   # look at the 90 row from Y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Activation is the sigmoid function σ(s) = 1/(1+exp(-s)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sigmoid function and its derivative\n",
    "σ(s) = 1/(1+exp(-s))\n",
    "dσ(s) = σ(s)*(1 - σ(s))\n",
    "\n",
    "# Define softmax function\n",
    "softmax(a, i) = exp(a[i])/(sum(exp(a[j]) for j = 1:length(a)))\n",
    "\n",
    "# Define cross-entropy loss function\n",
    "L(O, y) = -sum(y[i]*log(O[i]) for i = 1:length(y))\n",
    "\n",
    "# Define Hadamard Product\n",
    "hadamard(x,y) = [x[i]*y[i] for i = 1:length(x)];"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "forward_propagation (generic function with 1 method)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function forward_propagation(x, y, W, b)\n",
    "    a1 = copy(x)\n",
    "    z2 = W[1]*a1 + b[1]\n",
    "    a2 = σ.(z2)\n",
    "    \n",
    "    z3 = W[2]*a2 + b[2]\n",
    "    a3 = σ.(z3)\n",
    "    \n",
    "    z4 = W[3]*a3 + b[3]\n",
    "    a4 = σ.(z4)\n",
    "    \n",
    "    a = [a1, a2, a3, a4]\n",
    "    z = [[0.0], z2, z3, z4]\n",
    "    O = [softmax(a4, i) for i = 1:length(a4)]\n",
    "    loss = L(O, y)\n",
    "    return a, z, O, loss\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Array{Float64,1}[[5.1, 3.5, 1.4, 0.2], [0.518936, 0.999229, 0.998986, 0.981069, 0.975397], [0.810219, 0.820909, 0.658624, 0.736097, 0.732109], [0.828315, 0.567058, 0.699447]], Array{Float64,1}[[0.0], [0.0757783, 7.16726, 6.89309, 3.94783, 3.67996], [1.45143, 1.52251, 0.657169, 1.02578, 1.00535], [1.57374, 0.269857, 0.844666]], [0.377476, 0.290688, 0.331836], 0.9742471683443287)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forward_propagation(X[:,1], Y[:,1], W, b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "gradient_descent! (generic function with 1 method)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function backpropagation(x, y, W, b)\n",
    "    a, z, O, loss = forward_propagation(x, y, W, b)\n",
    "    δ4 = a[4] - y\n",
    "    δ3 = hadamard(W[3]'*δ4, dσ.(z[3]))\n",
    "    δ2 = hadamard(W[2]'*δ3, dσ.(z[2]))\n",
    "    δ = [[0.0], δ2, δ3, δ4]\n",
    "    return a, δ\n",
    "end\n",
    "\n",
    "function ∇L(x, y, W, b)\n",
    "\n",
    "    a, δ = backpropagation(x, y, W, b)\n",
    "    \n",
    "    db1 = copy(δ[2])\n",
    "    db2 = copy(δ[3])\n",
    "    db3 = copy(δ[4])\n",
    "    \n",
    "    dW1 = δ[2]*a[1]'\n",
    "    dW2 = δ[3]*a[2]'\n",
    "    dW3 = δ[4]*a[3]'\n",
    "    return [db1, db2, db3], [dW1, dW2, dW3]\n",
    "end\n",
    "\n",
    "\n",
    "function gradient_descent!(x, y, W, b, α)\n",
    "    db, dW = ∇L(x, y, W, b)\n",
    "    for i = 1:length(W)\n",
    "        W[i] -= α*dW[i]\n",
    "        b[i] -= α*b[i]\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mini_batch_∇L (generic function with 1 method)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function mini_batch_∇L(train_data, train_label, W, b, m)\n",
    "\n",
    "    i = rand(1:100)\n",
    "    a, δ = backpropagation(train_data[:,i], train_label[:,i], W, b)\n",
    "    \n",
    "    db1 = δ[2]\n",
    "    db2 = δ[3]\n",
    "    db3 = δ[4]\n",
    "    \n",
    "    dW1 = δ[2]*a[1]'\n",
    "    dW2 = δ[3]*a[2]'\n",
    "    dW3 = δ[4]*a[3]'\n",
    "    \n",
    "    for _ in 1:m\n",
    "        j = rand(1:100)\n",
    "        a, δ = backpropagation(train_data[:,j], train_label[:,j], W, b)\n",
    "    \n",
    "        db1 += copy(δ[2])\n",
    "        db2 += copy(δ[3])\n",
    "        db3 += copy(δ[4])\n",
    "    \n",
    "        dW1 += δ[2]*a[1]'\n",
    "        dW2 += δ[3]*a[2]'\n",
    "        dW3 += δ[4]*a[3]'\n",
    "    end\n",
    "    \n",
    "    return [db1/m, db2/m, db3/m], [dW1/m, dW2/m, dW3/m]\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "stochastic_gradient_descent! (generic function with 1 method)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function stochastic_gradient_descent!(train_data, train_label, W, b, α, m)\n",
    "    db , dW = mini_batch_∇L(train_data, train_label, W, b, m)\n",
    "    for i = 1:length(W)\n",
    "        W[i] -= α*dW[i]\n",
    "        b[i] -= α*b[i]\n",
    "    end\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Array{Float64,1},1}:\n",
       " [-1.0, -1.0, -1.0, -1.0, -1.0]\n",
       " [-1.0, -1.0, -1.0, -1.0, -1.0]\n",
       " [-1.0, -1.0, -1.0]            "
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize weight matrices \n",
    "W1 = rand(5, 4)\n",
    "W2 = rand(5, 5)\n",
    "W3 = rand(3, 5)\n",
    "W = [W1, W2, W3]\n",
    "\n",
    "# Initialize bias \n",
    "b1 = -1*ones(5)\n",
    "b2 = -1*ones(5)\n",
    "b3 = -1*ones(3)\n",
    "b = [b1, b2, b3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "make_prediction (generic function with 1 method)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "function make_prediction(i)\n",
    "    output = forward_propagation(X[:,i], Y[:,i], W, b)[3]\n",
    "    println(\"      setosa       |     versicolor       |     virginica\")\n",
    "    println(\"----------------------------------------------------------------\")\n",
    "    println(output[1],\" | \", output[2], \"  |  \", output[3])\n",
    "end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _ in 1:1000000\n",
    "    j = rand(1:150)\n",
    "    gradient_descent!(X[:,j], Y[:,j], W, b, 0.37)\n",
    "end\n",
    "#verified up to 35:39"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      setosa       |     versicolor       |     virginica\n",
      "----------------------------------------------------------------\n",
      "0.5761150276183369 | 0.21194258042827416  |  0.21194239195338885\n"
     ]
    }
   ],
   "source": [
    "make_prediction(12)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 1.0.3",
   "language": "julia",
   "name": "julia-1.0"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "1.0.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

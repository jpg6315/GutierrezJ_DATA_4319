{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"left\" width=\"300\" height=\"2000\" src=\"TF_f.png\">\n",
    "&nbsp;                                                                                                                            \n",
    "&nbsp;\n",
    "\n",
    "<center> <h1>TENSOR FLOW</h1> </center> \n",
    "<center> <h1>in PYTHON</h1> </center>\n",
    "&nbsp;                                                                                                                            \n",
    "&nbsp;\n",
    "&nbsp;\n",
    "&nbsp;\n",
    "&nbsp;\n",
    "&nbsp;\n",
    "&nbsp;\n",
    "&nbsp;                                                                                                                            \n",
    "&nbsp;\n",
    "&nbsp;\n",
    "&nbsp;\n",
    "&nbsp;\n",
    "&nbsp;\n",
    "&nbsp;\n",
    "&nbsp;\n",
    "&nbsp; \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### API Application Program Interface\n",
    "Tensor Flow uses three main API's that Keras, Lego-like building block for building and defining models, tf.data is an easy input pipeline and Eager execution, which makes TensorFlow feel like regular Python.\n",
    "&nbsp;\n",
    "&nbsp;\n",
    "\n",
    "Dr. Randy Davila pointed out that going to Colab.research.google.com which is baiscally a virtural enviorment where you can write your neural network. The advantages is that the site already has the packages, pip's, snippets and access to GPU's.\n",
    "&nbsp;\n",
    "&nbsp;\n",
    "\n",
    "Thoughtfully designing an experiment is much more important than the accuracy. What are you trying to predict and why; how will it be used in practice; what could go wrong and why; and where did the data come from.\n",
    "&nbsp;\n",
    "&nbsp;\n",
    "\n",
    "Steps to writing neural network\n",
    "1. Collect a data set\n",
    "2. Build your model\n",
    "3. Train\n",
    "4. Evaluate\n",
    "5. Predict\n",
    "&nbsp;\n",
    "&nbsp;\n",
    "\n",
    "Using MNIST Data Set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img align=\"center\" width=\"700\" height=\"2000\" src=\"mnist.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Step 1 Data\n",
    "Build the data set.\n",
    "\n",
    "<img align=\"center\" width=\"700\" height=\"2000\" src=\"step1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Step 2 Building Model\n",
    "The optimizer used is adam - an optimization algorithm that can used instead of the classical stochastic gradient descent procedure to update network weights iterative based in training data. \n",
    "<img align=\"center\" width=\"700\" height=\"2000\" src=\"step1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Step 3 Train Data\n",
    "This one line trains the model. The only parameter that matters is epoch, which means one sweep across the network. Loss is that same as error.\n",
    "<img align=\"center\" width=\"700\" height=\"2000\" src=\"step3.png\">\n",
    "&nbsp;                                                                                                                            \n",
    "&nbsp;\n",
    "&nbsp;\n",
    "&nbsp;\n",
    "&nbsp;\n",
    "&nbsp;\n",
    "&nbsp;\n",
    "<img align=\"center\" width=\"700\" height=\"2000\" src=\"step3_epoch.png\">\n",
    "&nbsp;                                                                                                                            \n",
    "&nbsp;\n",
    "&nbsp;\n",
    "&nbsp;\n",
    "&nbsp;\n",
    "&nbsp;\n",
    "&nbsp;\n",
    "&nbsp;\n",
    "&nbsp; \n",
    "Loss is that same as error. The idea is that the model iterates across the sweet spot and finds the extrema, the smallest loss.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Step 4 Evaluate\n",
    "Given some new data, classify with network and take a look at accuracy. This will give loss and error. This model has an accuracy of 98 percent classification.\n",
    "<img align=\"center\" width=\"700\" height=\"2000\" src=\"step4.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Step 5 Predict\n",
    "Makes a prediction of character to the data set.\n",
    "<img align=\"center\" width=\"700\" height=\"2000\" src=\"step4.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\jpg63\\Anaconda3\\envs\\tensoflow\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\jpg63\\Anaconda3\\envs\\tensoflow\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 10s 166us/sample - loss: 0.2194 - acc: 0.9351\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 10s 168us/sample - loss: 0.0959 - acc: 0.9704\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 9s 156us/sample - loss: 0.0691 - acc: 0.9782\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 10s 164us/sample - loss: 0.0528 - acc: 0.9825\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 10s 163us/sample - loss: 0.0430 - acc: 0.9862\n",
      "10000/10000 [==============================] - 0s 49us/sample - loss: 0.0750 - acc: 0.9786\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.0749650876199943, 0.9786]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#***** DO NOT RUN CELL UNLESS YOU HAVE TIME TO STAND-BY********\n",
    "\n",
    "import tensorflow as tf                                      #Step1 import tensorflow\n",
    "mnist = tf.keras.datasets.mnist                              #importing mnist included into tensorflow\n",
    "\n",
    "(x_train, y_train),(x_test, y_test) = mnist.load_data()\n",
    "x_train, x_test = x_train / 255.0, x_test / 255.0\n",
    "\n",
    "model = tf.keras.models.Sequential([                          #Step 2 Build the model\n",
    "  tf.keras.layers.Flatten(input_shape=(28, 28)),              #takes input and puts it into vector\n",
    "  tf.keras.layers.Dense(512, activation=tf.nn.relu),\n",
    "  tf.keras.layers.Dropout(0.2),\n",
    "  tf.keras.layers.Dense(10, activation=tf.nn.softmax)\n",
    "])\n",
    "model.compile(optimizer='adam',                               #compile the network compare the thing that the networ\n",
    "              loss='sparse_categorical_crossentropy',         #predicted to the thing you wanted it to predict\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train, epochs=5)                         #Step3 train data\n",
    "model.evaluate(x_test, y_test)                                #Step4 evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.2198483e-08, 6.2375932e-07, 1.9702720e-05, 2.7362552e-07,\n",
       "       9.9854589e-01, 1.4648179e-08, 2.4020858e-07, 2.2372507e-05,\n",
       "       1.2853000e-07, 1.4107871e-03], dtype=float32)"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predict=model.predict(x_train[0:9])                           #step5 predict\n",
    "predict[2]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
